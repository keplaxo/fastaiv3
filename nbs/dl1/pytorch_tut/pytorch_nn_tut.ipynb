{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can be constructed using the torch.nn package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you had a glimpse of autograd, nn depends on autograd to define models and differentiate them. An nn.Module contains layers, and a method forward(input)that returns the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "Define the neural network that has some learnable parameters (or weights)\n",
    "Iterate over a dataset of inputs\n",
    "Process input through the network\n",
    "Compute the loss (how far is the output from being correct)\n",
    "Propagate gradients back into the networkâ€™s parameters\n",
    "Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Net"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    \"\"\"A simple example class\"\"\"\n",
    "    i = 12345\n",
    "\n",
    "    def f(self):\n",
    "        return 'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = MyClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12345"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MyClass.f of <__main__.MyClass object at 0x7f44895aa860>>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english.f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A simple example class'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, -4.5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Complex:\n",
    "    def __init__(self, realpart, imagpart):\n",
    "        self.r = realpart\n",
    "        self.i = imagpart\n",
    "\n",
    "x = Complex(3.0, -4.5)\n",
    "x.r, x.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Net"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e190893001f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 539\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just have to define the forward function, and the backward function (where gradients are computed) is automatically defined for you using autograd. You can use any of the Tensor operations in the forward function. The learnable parameters of a model are returned by net.parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[ 0.1820,  0.3204, -0.0876],\n",
       "           [ 0.1302, -0.2102,  0.3298],\n",
       "           [ 0.0571,  0.0613,  0.3190]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1820,  0.1108, -0.3210],\n",
       "           [ 0.0065, -0.2209,  0.0598],\n",
       "           [-0.3203, -0.1176, -0.3291]]],\n",
       " \n",
       " \n",
       "         [[[-0.3268, -0.2073,  0.1530],\n",
       "           [-0.1213,  0.0338,  0.3159],\n",
       "           [ 0.0342, -0.2437,  0.3053]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1991,  0.3117,  0.2914],\n",
       "           [ 0.1860,  0.0556,  0.2291],\n",
       "           [-0.1520, -0.2864,  0.1950]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3260, -0.2041,  0.1493],\n",
       "           [-0.0361, -0.0236,  0.3070],\n",
       "           [ 0.0159,  0.1547,  0.0891]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0544, -0.0118,  0.3191],\n",
       "           [-0.2764,  0.2337, -0.0414],\n",
       "           [ 0.0918,  0.0845,  0.0688]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3264, -0.1917,  0.1186,  0.1169, -0.2070, -0.0095],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 4.0744e-04,  3.1800e-02,  9.9920e-02],\n",
       "           [-4.2151e-02,  5.3741e-02, -4.3276e-02],\n",
       "           [-3.6952e-02, -6.2339e-02, -3.1938e-02]],\n",
       " \n",
       "          [[ 5.6740e-02, -1.2863e-01, -5.9400e-02],\n",
       "           [-9.0484e-03, -1.1572e-01,  1.0608e-01],\n",
       "           [ 6.1742e-02, -8.6927e-02, -9.3534e-02]],\n",
       " \n",
       "          [[ 1.2135e-01, -1.7144e-02,  2.5406e-02],\n",
       "           [-4.1477e-03, -1.1940e-01, -1.1375e-01],\n",
       "           [ 1.3541e-01, -7.6639e-02, -1.3410e-01]],\n",
       " \n",
       "          [[-1.2604e-02, -2.2428e-02, -5.1618e-02],\n",
       "           [-1.0414e-01, -1.0349e-01, -1.0945e-01],\n",
       "           [ 4.5417e-02,  1.9477e-02, -8.8653e-02]],\n",
       " \n",
       "          [[ 4.0196e-02,  1.9144e-02,  1.2942e-01],\n",
       "           [-1.0675e-01,  1.0793e-01, -6.3566e-02],\n",
       "           [ 1.1319e-01, -9.9836e-02, -3.7118e-02]],\n",
       " \n",
       "          [[-1.0803e-01,  7.9545e-02, -9.8172e-02],\n",
       "           [ 2.2241e-03,  6.0379e-02,  1.2685e-01],\n",
       "           [ 2.9658e-02, -1.0365e-01, -1.1929e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 7.2924e-03, -9.5369e-02,  1.0548e-01],\n",
       "           [-4.7308e-02,  8.2203e-03,  1.3510e-01],\n",
       "           [ 6.2273e-02,  1.5879e-02, -1.9531e-02]],\n",
       " \n",
       "          [[ 6.1609e-02, -1.1612e-01,  2.8238e-02],\n",
       "           [ 1.3211e-02,  9.4381e-02, -9.9464e-02],\n",
       "           [-1.9881e-03, -1.2732e-01,  8.5390e-02]],\n",
       " \n",
       "          [[ 8.7484e-02,  9.7535e-02, -9.2477e-02],\n",
       "           [-1.2732e-01,  2.0678e-02,  6.5165e-03],\n",
       "           [-3.4918e-02,  6.2660e-02, -8.2516e-02]],\n",
       " \n",
       "          [[-1.1763e-01,  1.3497e-01,  1.3274e-01],\n",
       "           [ 5.6723e-02, -6.4348e-02, -9.8110e-02],\n",
       "           [-1.3304e-01,  9.4926e-02, -5.0256e-02]],\n",
       " \n",
       "          [[-7.0683e-02, -2.7738e-02,  1.2863e-01],\n",
       "           [-1.2517e-01, -1.8519e-02, -5.6692e-02],\n",
       "           [ 9.0124e-02,  1.8717e-02, -1.2714e-01]],\n",
       " \n",
       "          [[-4.9723e-02, -5.0414e-02, -5.3069e-02],\n",
       "           [ 3.8701e-03, -3.8176e-02, -1.1711e-01],\n",
       "           [-2.1247e-03, -1.2578e-01,  1.0004e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 6.7814e-02,  3.6868e-02,  9.0274e-02],\n",
       "           [-2.3116e-02, -2.5852e-02,  9.9184e-02],\n",
       "           [ 1.4379e-02,  9.5883e-02,  6.8013e-02]],\n",
       " \n",
       "          [[-1.3384e-03, -1.0108e-01, -5.5840e-03],\n",
       "           [ 7.2735e-02,  1.2110e-01, -1.0238e-01],\n",
       "           [-1.1510e-01, -1.1484e-01,  5.8910e-03]],\n",
       " \n",
       "          [[-6.1353e-02,  5.3259e-02,  1.1311e-02],\n",
       "           [-9.4472e-02, -3.3696e-03,  1.9607e-02],\n",
       "           [-8.3092e-02,  2.0016e-02,  3.3830e-02]],\n",
       " \n",
       "          [[-1.0631e-01,  1.1531e-01, -8.0791e-02],\n",
       "           [ 1.1616e-01,  8.3539e-02,  9.0171e-03],\n",
       "           [ 7.5609e-02,  1.3157e-01, -8.3317e-02]],\n",
       " \n",
       "          [[ 1.3326e-01, -6.6960e-02, -6.7996e-02],\n",
       "           [ 1.0249e-01, -5.6415e-02,  7.8743e-02],\n",
       "           [-2.1245e-02,  1.2834e-01, -1.1480e-01]],\n",
       " \n",
       "          [[-5.4799e-03,  9.0525e-05,  6.3983e-02],\n",
       "           [-1.2867e-01,  1.3532e-01,  5.4939e-02],\n",
       "           [-1.2856e-01,  1.0560e-01,  1.1474e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 9.8644e-02,  2.6479e-02, -6.0577e-02],\n",
       "           [-1.0846e-01,  1.2479e-01,  1.9416e-02],\n",
       "           [ 6.1103e-02,  5.9487e-02, -5.0910e-02]],\n",
       " \n",
       "          [[-7.4545e-02,  2.1709e-02,  9.4122e-02],\n",
       "           [-1.1919e-01,  1.2854e-01,  6.3936e-02],\n",
       "           [ 5.1175e-02, -5.6276e-02, -6.7618e-03]],\n",
       " \n",
       "          [[-5.2992e-02,  9.4487e-02, -7.9097e-02],\n",
       "           [ 1.3272e-01, -1.0046e-01,  1.1303e-01],\n",
       "           [ 9.1215e-03,  6.4012e-02, -1.8944e-02]],\n",
       " \n",
       "          [[ 1.2177e-02,  1.0245e-01,  2.2330e-02],\n",
       "           [-3.4758e-02, -5.1448e-02, -9.3090e-02],\n",
       "           [-1.2453e-01,  1.1346e-01,  4.8930e-02]],\n",
       " \n",
       "          [[-5.1140e-02, -3.9822e-03,  8.7218e-02],\n",
       "           [-7.7109e-02, -1.9319e-02,  7.0785e-02],\n",
       "           [ 8.4337e-02, -1.9392e-02, -1.3589e-01]],\n",
       " \n",
       "          [[-2.9855e-02, -3.9959e-02, -6.8268e-02],\n",
       "           [-5.3287e-02,  8.6206e-02,  5.0957e-02],\n",
       "           [ 4.2916e-02,  1.0164e-01, -5.9540e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.5117e-02, -7.9593e-02, -1.2660e-01],\n",
       "           [-1.0103e-01,  4.2470e-02,  2.4942e-02],\n",
       "           [-1.0075e-01, -1.3986e-02,  4.9831e-02]],\n",
       " \n",
       "          [[-3.6459e-03, -8.8425e-02, -1.5001e-03],\n",
       "           [-7.3995e-02, -6.9472e-02,  5.1024e-02],\n",
       "           [-5.4617e-02, -6.0813e-02, -6.2332e-02]],\n",
       " \n",
       "          [[ 5.2827e-02, -1.3322e-01,  1.1436e-02],\n",
       "           [-1.1438e-01,  3.8352e-02, -1.1141e-01],\n",
       "           [-5.5091e-02, -9.1387e-02,  6.8020e-02]],\n",
       " \n",
       "          [[-1.2393e-01,  8.0474e-02, -8.9684e-02],\n",
       "           [-1.2865e-01, -4.8385e-02, -6.9818e-02],\n",
       "           [-7.8131e-02, -8.5605e-02,  3.7622e-02]],\n",
       " \n",
       "          [[-9.3042e-02, -2.9603e-03, -4.7897e-02],\n",
       "           [-1.4482e-02,  8.1535e-02,  5.4489e-02],\n",
       "           [ 4.5535e-02,  6.8289e-02, -5.2937e-02]],\n",
       " \n",
       "          [[ 2.8416e-02, -3.4901e-02, -8.4877e-02],\n",
       "           [ 4.5167e-02, -9.0026e-02,  6.8887e-02],\n",
       "           [-1.3032e-01,  1.3598e-01,  3.9962e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.5813e-02,  1.2226e-01,  1.2673e-01],\n",
       "           [ 3.5762e-02, -1.1248e-01, -5.7225e-02],\n",
       "           [ 4.6343e-02, -6.1660e-02, -1.6444e-02]],\n",
       " \n",
       "          [[ 7.6415e-02, -1.2209e-01,  9.5357e-02],\n",
       "           [ 1.3605e-02,  4.7575e-02,  1.3611e-02],\n",
       "           [-4.6378e-02, -9.6754e-02, -1.3579e-01]],\n",
       " \n",
       "          [[ 1.2437e-01,  3.7782e-03, -4.9333e-02],\n",
       "           [ 9.9554e-02, -4.7880e-02,  1.1484e-01],\n",
       "           [ 6.4661e-02, -5.6681e-02, -9.3663e-02]],\n",
       " \n",
       "          [[ 7.2700e-02,  4.1770e-02,  8.5469e-02],\n",
       "           [-1.4386e-02, -6.9883e-02,  6.8406e-02],\n",
       "           [-1.6213e-02, -3.5239e-02,  6.2336e-02]],\n",
       " \n",
       "          [[ 6.1699e-02,  3.0395e-02,  1.0408e-01],\n",
       "           [-2.7392e-02, -9.7833e-02, -1.5234e-02],\n",
       "           [ 3.1980e-03,  7.8151e-02, -5.5790e-02]],\n",
       " \n",
       "          [[ 1.0007e-01, -8.9486e-02,  1.3898e-02],\n",
       "           [ 7.8197e-02, -9.2576e-02, -4.3231e-02],\n",
       "           [ 6.3630e-02, -4.0142e-02, -9.7196e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2943e-01, -9.2375e-03,  1.0343e-02],\n",
       "           [ 4.0146e-02, -9.8511e-03, -3.6031e-02],\n",
       "           [-1.0135e-01, -1.1112e-01, -1.2590e-01]],\n",
       " \n",
       "          [[-1.8441e-02,  4.1943e-03, -1.1877e-01],\n",
       "           [ 2.9768e-02,  8.9950e-02,  2.2800e-02],\n",
       "           [ 8.8468e-02, -6.0424e-02,  4.7804e-02]],\n",
       " \n",
       "          [[-1.2832e-01, -3.0821e-02,  3.8396e-02],\n",
       "           [-3.1757e-02,  1.1178e-01, -1.3360e-01],\n",
       "           [ 1.0179e-01,  8.1996e-02, -6.7246e-02]],\n",
       " \n",
       "          [[ 7.6889e-02, -6.4783e-02, -2.1545e-02],\n",
       "           [ 5.1452e-02,  1.3423e-01,  6.9005e-02],\n",
       "           [-5.7310e-02,  1.0229e-01, -7.7874e-02]],\n",
       " \n",
       "          [[-2.0018e-02,  1.0660e-01,  6.4233e-02],\n",
       "           [-6.5151e-02, -1.2860e-01, -9.8468e-02],\n",
       "           [ 1.2034e-01,  1.1412e-01,  8.0544e-02]],\n",
       " \n",
       "          [[ 2.7860e-02,  8.4691e-02, -7.9061e-02],\n",
       "           [-6.7964e-02,  4.1731e-02,  1.1698e-02],\n",
       "           [-1.1113e-01,  1.2915e-01, -1.2805e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3499e-01, -4.6928e-02,  4.0813e-02],\n",
       "           [-3.1907e-02, -1.0866e-01,  2.5322e-02],\n",
       "           [-7.0226e-03, -1.4401e-02, -8.2491e-02]],\n",
       " \n",
       "          [[ 4.8331e-02,  3.0819e-02,  2.0967e-02],\n",
       "           [ 5.1499e-02,  4.4541e-02, -1.2836e-01],\n",
       "           [-3.6767e-03, -8.5430e-02, -2.2638e-02]],\n",
       " \n",
       "          [[-1.1808e-01,  8.9831e-02,  1.3376e-01],\n",
       "           [ 3.1941e-02,  1.3472e-03,  9.4181e-02],\n",
       "           [ 4.7711e-04, -3.3717e-02,  1.1949e-01]],\n",
       " \n",
       "          [[-6.0239e-02, -1.0388e-01,  2.2659e-02],\n",
       "           [ 6.6780e-02,  4.8992e-02,  3.1988e-02],\n",
       "           [ 1.1936e-01,  1.0146e-01, -1.0672e-01]],\n",
       " \n",
       "          [[-1.0549e-01,  1.1131e-01, -9.3636e-02],\n",
       "           [ 5.6319e-02,  1.9722e-02, -1.2355e-02],\n",
       "           [ 1.1598e-01,  2.7699e-02, -6.4367e-02]],\n",
       " \n",
       "          [[-6.9412e-02, -1.1843e-02,  9.4694e-02],\n",
       "           [-1.2492e-01,  2.8592e-02,  1.3411e-01],\n",
       "           [-1.2050e-01,  7.0964e-02, -4.3924e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.5435e-02, -5.2850e-02,  1.0376e-01],\n",
       "           [-8.3883e-02,  4.5836e-02, -6.7920e-02],\n",
       "           [ 2.1193e-02,  9.6586e-02, -1.1065e-01]],\n",
       " \n",
       "          [[ 1.2931e-01,  3.7612e-02, -1.0270e-01],\n",
       "           [ 1.0738e-01,  1.0256e-01, -1.0296e-01],\n",
       "           [ 1.3265e-01,  3.6433e-02, -5.0950e-02]],\n",
       " \n",
       "          [[-1.0465e-01, -1.2335e-01, -1.1992e-01],\n",
       "           [ 5.1131e-02, -1.0437e-01, -2.8576e-03],\n",
       "           [-3.8627e-02, -7.4916e-02, -2.5591e-02]],\n",
       " \n",
       "          [[-1.3365e-03,  2.3856e-02, -7.6008e-02],\n",
       "           [ 1.1647e-01, -5.8506e-02, -8.7364e-02],\n",
       "           [-7.5222e-02, -2.8145e-02,  9.4341e-02]],\n",
       " \n",
       "          [[ 7.5900e-02, -9.7155e-02,  2.1187e-02],\n",
       "           [ 2.3161e-02,  3.8050e-02,  1.2626e-01],\n",
       "           [-4.2569e-02,  3.9295e-02,  6.6752e-03]],\n",
       " \n",
       "          [[-1.0733e-01, -9.5421e-02,  6.3318e-02],\n",
       "           [ 1.8050e-02,  1.1362e-01, -1.1387e-01],\n",
       "           [ 5.0714e-02,  1.0855e-01,  6.7408e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.5305e-02,  1.2960e-01,  6.9148e-02],\n",
       "           [-1.3249e-01,  1.3525e-01, -7.6172e-02],\n",
       "           [ 4.7473e-02,  1.3495e-01, -5.3011e-02]],\n",
       " \n",
       "          [[ 4.9688e-02,  3.4174e-02,  1.5693e-02],\n",
       "           [ 2.7843e-02, -1.1817e-01, -9.9263e-02],\n",
       "           [ 1.1023e-01, -1.2178e-01, -1.3211e-01]],\n",
       " \n",
       "          [[-3.6319e-02,  2.3206e-02,  2.3204e-02],\n",
       "           [-5.6185e-02,  6.2800e-02,  3.1796e-02],\n",
       "           [-1.3486e-01, -1.0582e-01, -9.3132e-02]],\n",
       " \n",
       "          [[ 1.0379e-03,  4.2546e-02, -1.2291e-01],\n",
       "           [-1.1854e-01,  9.6618e-02,  8.9078e-02],\n",
       "           [-2.2134e-02, -1.0124e-01,  8.7870e-02]],\n",
       " \n",
       "          [[-2.8874e-02,  2.5337e-02, -2.7309e-02],\n",
       "           [ 1.2171e-01,  1.2088e-01, -6.5330e-02],\n",
       "           [ 1.3346e-01,  8.4968e-02,  1.3349e-01]],\n",
       " \n",
       "          [[-2.2197e-02,  7.2092e-02, -1.3052e-01],\n",
       "           [-7.9436e-02,  1.7178e-02, -7.4304e-02],\n",
       "           [ 7.9196e-03, -1.0607e-01,  5.2331e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2986e-01,  4.9243e-02,  9.9934e-02],\n",
       "           [-6.9243e-02, -3.8182e-03,  8.2302e-03],\n",
       "           [-1.0355e-01,  3.4196e-02, -1.0894e-01]],\n",
       " \n",
       "          [[-1.3408e-01,  4.2912e-02, -4.4252e-03],\n",
       "           [-4.9991e-02,  1.2258e-01, -1.1416e-01],\n",
       "           [ 6.7740e-02,  1.0934e-01, -1.1372e-01]],\n",
       " \n",
       "          [[ 1.3570e-01,  7.9408e-02, -2.8986e-02],\n",
       "           [-1.0108e-01,  2.4630e-02, -5.7081e-02],\n",
       "           [-8.5032e-02, -7.5864e-03,  8.6277e-02]],\n",
       " \n",
       "          [[-3.2318e-02, -1.0541e-01,  8.0929e-02],\n",
       "           [-1.1202e-01,  6.4925e-02, -7.6988e-02],\n",
       "           [-1.2999e-01, -1.0050e-01, -1.3293e-01]],\n",
       " \n",
       "          [[ 2.3385e-02,  5.2107e-02,  1.1594e-01],\n",
       "           [ 9.3965e-02, -1.7720e-02, -1.0163e-01],\n",
       "           [-5.9717e-02, -5.1283e-02,  8.9203e-03]],\n",
       " \n",
       "          [[-1.7047e-02,  1.1228e-01, -1.1696e-01],\n",
       "           [-1.3598e-01,  1.0867e-01,  4.1560e-02],\n",
       "           [ 1.1947e-01, -2.4230e-02,  1.2329e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 7.3842e-03,  1.3359e-01,  6.0975e-02],\n",
       "           [-1.2291e-01, -7.3355e-02,  3.5246e-02],\n",
       "           [ 6.2331e-02,  7.4318e-03, -1.0802e-01]],\n",
       " \n",
       "          [[-2.3101e-02, -5.8454e-03, -1.7057e-02],\n",
       "           [-1.0450e-01,  2.2271e-02,  5.9180e-02],\n",
       "           [-2.1012e-02,  1.2218e-01, -9.9029e-02]],\n",
       " \n",
       "          [[ 7.8264e-02, -8.3025e-02,  1.1251e-01],\n",
       "           [-1.0972e-02, -6.9790e-02,  1.0636e-01],\n",
       "           [-1.0720e-01, -3.3921e-02,  7.4570e-02]],\n",
       " \n",
       "          [[-1.5867e-02,  2.3750e-02,  9.3569e-02],\n",
       "           [ 1.0674e-01,  2.0538e-02,  7.7723e-02],\n",
       "           [-3.6801e-02, -1.3030e-01,  3.0214e-02]],\n",
       " \n",
       "          [[-6.3805e-02, -9.6936e-02,  3.4882e-02],\n",
       "           [ 1.2507e-01, -7.4618e-02, -4.8944e-02],\n",
       "           [ 7.1024e-02,  5.2630e-02, -4.8606e-02]],\n",
       " \n",
       "          [[ 1.2666e-01, -1.0412e-01,  3.2973e-02],\n",
       "           [ 1.0607e-01, -9.5914e-02,  7.4008e-02],\n",
       "           [ 7.1712e-02,  7.4460e-02, -7.5448e-02]]],\n",
       " \n",
       " \n",
       "         [[[-6.3290e-02, -3.0426e-02, -1.1312e-01],\n",
       "           [ 8.4370e-02, -1.9086e-02, -1.1871e-01],\n",
       "           [ 3.9600e-02, -7.3853e-02, -4.3786e-03]],\n",
       " \n",
       "          [[-7.6174e-02,  6.2499e-02, -3.0046e-02],\n",
       "           [-6.6297e-02, -1.3794e-02,  1.0009e-01],\n",
       "           [ 1.1910e-01,  3.4531e-02, -1.2363e-01]],\n",
       " \n",
       "          [[-3.5032e-02,  1.0658e-01, -1.9061e-02],\n",
       "           [ 5.9922e-02, -4.4271e-02,  6.7193e-02],\n",
       "           [-1.3216e-01,  5.8114e-02,  4.7915e-02]],\n",
       " \n",
       "          [[ 1.1453e-01, -1.3302e-01,  1.0517e-01],\n",
       "           [ 1.2892e-01, -1.1069e-02, -6.8340e-02],\n",
       "           [-3.5886e-02, -6.1972e-02,  8.6925e-02]],\n",
       " \n",
       "          [[-1.3300e-01, -2.8646e-02, -4.1669e-02],\n",
       "           [ 4.1520e-02, -2.0799e-02, -4.7096e-02],\n",
       "           [-6.1245e-02, -6.2942e-02, -1.0423e-01]],\n",
       " \n",
       "          [[ 5.8391e-02, -5.8146e-02,  9.9333e-02],\n",
       "           [ 1.9734e-02, -8.9951e-02, -5.1154e-02],\n",
       "           [-7.9062e-03, -7.2889e-02,  9.5908e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.1338e-02, -8.5007e-02, -7.3349e-02],\n",
       "           [ 9.0687e-02, -5.6922e-02,  1.1680e-02],\n",
       "           [-9.6750e-02,  5.8659e-02,  1.1723e-01]],\n",
       " \n",
       "          [[ 1.1046e-01, -1.1512e-02, -1.9001e-02],\n",
       "           [ 1.5319e-02, -1.1182e-01,  8.8410e-02],\n",
       "           [-6.9277e-02, -3.3903e-02, -8.6217e-02]],\n",
       " \n",
       "          [[-1.0055e-01,  1.0251e-01,  1.2429e-01],\n",
       "           [ 6.8921e-02,  8.2206e-02,  1.0954e-01],\n",
       "           [-8.3023e-02,  9.2749e-02,  5.1331e-02]],\n",
       " \n",
       "          [[ 1.1960e-01,  1.3082e-01,  4.8050e-02],\n",
       "           [-5.1905e-02,  1.1003e-01,  9.2708e-02],\n",
       "           [-1.2634e-01, -1.3499e-02, -3.2761e-02]],\n",
       " \n",
       "          [[-4.1961e-02, -7.6891e-03, -7.8853e-02],\n",
       "           [ 9.9759e-02, -4.3578e-02, -1.2429e-02],\n",
       "           [ 3.6914e-03, -4.2520e-02, -1.1303e-01]],\n",
       " \n",
       "          [[-7.9447e-02,  7.3356e-02,  4.2622e-02],\n",
       "           [ 6.1245e-02, -1.2987e-01, -1.3396e-01],\n",
       "           [-1.1135e-01, -9.1448e-05,  4.7731e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0451e-01, -1.1514e-01, -3.5832e-02],\n",
       "           [ 1.3012e-01, -9.5567e-04,  9.8269e-03],\n",
       "           [ 2.2694e-03, -8.5715e-02,  3.3157e-02]],\n",
       " \n",
       "          [[ 9.3149e-02, -2.6114e-02,  1.1308e-01],\n",
       "           [ 6.5016e-02, -4.9598e-02,  7.2022e-02],\n",
       "           [ 1.2304e-01,  1.1247e-01,  6.5659e-02]],\n",
       " \n",
       "          [[ 6.7145e-02,  6.6467e-02,  5.6030e-02],\n",
       "           [ 8.8385e-02, -4.7971e-02, -9.4870e-03],\n",
       "           [ 2.5096e-02, -1.4422e-02,  7.9191e-02]],\n",
       " \n",
       "          [[-1.6352e-02,  4.1531e-02, -9.3821e-02],\n",
       "           [-1.3279e-01,  6.7294e-02,  1.1308e-01],\n",
       "           [-2.4662e-02, -9.8136e-02,  7.5386e-02]],\n",
       " \n",
       "          [[-3.0029e-02,  5.3417e-02,  3.0162e-03],\n",
       "           [ 1.8900e-02,  1.0305e-01,  1.1449e-01],\n",
       "           [-7.0123e-02, -7.3769e-02, -4.5869e-02]],\n",
       " \n",
       "          [[ 4.7109e-02,  1.3574e-01, -2.5629e-03],\n",
       "           [ 9.3413e-02,  7.0572e-02, -1.3132e-02],\n",
       "           [ 8.8849e-02,  3.0024e-02,  1.0614e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 8.5011e-02,  7.5501e-02, -8.6607e-02],\n",
       "           [-6.6879e-03, -4.9293e-02, -1.0861e-01],\n",
       "           [ 8.2191e-02, -1.1876e-01,  5.7246e-02]],\n",
       " \n",
       "          [[ 1.3447e-01, -4.5916e-03,  4.2845e-02],\n",
       "           [ 1.0780e-01,  8.5776e-03,  4.2283e-02],\n",
       "           [-4.9917e-02,  7.0464e-02, -1.5132e-03]],\n",
       " \n",
       "          [[-1.1518e-01,  4.3986e-02,  2.2964e-03],\n",
       "           [-1.2127e-01, -1.2348e-01,  2.8872e-02],\n",
       "           [ 9.5969e-02, -2.0505e-02, -8.3275e-02]],\n",
       " \n",
       "          [[-8.5387e-02,  4.6726e-02, -1.3119e-01],\n",
       "           [ 2.1433e-03,  7.1997e-02, -3.5647e-02],\n",
       "           [ 8.7229e-02, -1.1867e-01,  7.6786e-02]],\n",
       " \n",
       "          [[-1.0103e-01,  3.6826e-02,  1.3128e-02],\n",
       "           [ 7.9055e-02,  1.2502e-01,  9.6071e-02],\n",
       "           [-8.1837e-02, -1.2338e-01,  1.6424e-02]],\n",
       " \n",
       "          [[-1.1076e-01,  9.8094e-02, -8.2805e-02],\n",
       "           [ 1.1285e-01,  8.0453e-02, -8.5057e-02],\n",
       "           [-1.0310e-01, -1.2318e-01, -1.1710e-01]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0095, -0.0788, -0.0852,  0.1013,  0.0995, -0.0800, -0.0900,  0.0902,\n",
       "          0.1275,  0.0300, -0.0447,  0.0130, -0.0604,  0.0071,  0.0202, -0.0220],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0305, -0.0104, -0.0394,  ...,  0.0289,  0.0008,  0.0192],\n",
       "         [ 0.0090,  0.0122, -0.0087,  ...,  0.0093,  0.0014,  0.0025],\n",
       "         [-0.0272,  0.0277,  0.0319,  ..., -0.0075,  0.0230,  0.0277],\n",
       "         ...,\n",
       "         [-0.0146, -0.0156,  0.0306,  ..., -0.0341,  0.0254, -0.0068],\n",
       "         [-0.0170,  0.0279,  0.0356,  ...,  0.0082,  0.0036,  0.0324],\n",
       "         [ 0.0346,  0.0142,  0.0062,  ...,  0.0408, -0.0239, -0.0325]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0042,  0.0011,  0.0292, -0.0329,  0.0293,  0.0043,  0.0413, -0.0070,\n",
       "         -0.0182,  0.0324,  0.0247,  0.0330, -0.0003, -0.0191, -0.0337,  0.0147,\n",
       "          0.0181, -0.0391,  0.0173, -0.0375, -0.0291,  0.0204,  0.0125,  0.0408,\n",
       "         -0.0254,  0.0307, -0.0359,  0.0336,  0.0390, -0.0279,  0.0077,  0.0210,\n",
       "         -0.0142,  0.0265, -0.0225,  0.0404, -0.0169, -0.0032,  0.0327, -0.0280,\n",
       "          0.0046, -0.0213, -0.0134, -0.0173, -0.0316,  0.0263,  0.0357, -0.0196,\n",
       "         -0.0250, -0.0008, -0.0333,  0.0168,  0.0135, -0.0147,  0.0122, -0.0031,\n",
       "         -0.0024, -0.0339,  0.0384,  0.0126,  0.0128, -0.0394,  0.0299,  0.0314,\n",
       "          0.0300,  0.0275, -0.0273,  0.0129,  0.0301,  0.0300,  0.0073,  0.0386,\n",
       "         -0.0051, -0.0361,  0.0295, -0.0012, -0.0257, -0.0014,  0.0365,  0.0367,\n",
       "         -0.0179,  0.0310,  0.0322,  0.0039, -0.0324,  0.0006, -0.0099, -0.0282,\n",
       "          0.0150,  0.0266,  0.0048, -0.0164,  0.0263, -0.0107, -0.0033,  0.0049,\n",
       "          0.0271, -0.0364, -0.0140,  0.0367, -0.0056,  0.0008, -0.0065, -0.0186,\n",
       "          0.0013, -0.0002,  0.0250,  0.0069,  0.0177,  0.0354,  0.0010, -0.0174,\n",
       "          0.0129,  0.0300, -0.0373,  0.0199, -0.0049, -0.0270, -0.0379, -0.0385],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0729,  0.0675,  0.0100,  ...,  0.0797, -0.0781, -0.0609],\n",
       "         [ 0.0307,  0.0672,  0.0781,  ...,  0.0332,  0.0504, -0.0119],\n",
       "         [ 0.0589, -0.0649,  0.0308,  ...,  0.0664,  0.0667, -0.0225],\n",
       "         ...,\n",
       "         [ 0.0601,  0.0813, -0.0549,  ...,  0.0630, -0.0760,  0.0441],\n",
       "         [-0.0724, -0.0353, -0.0381,  ..., -0.0811,  0.0750,  0.0402],\n",
       "         [ 0.0068, -0.0491, -0.0783,  ..., -0.0267, -0.0194, -0.0272]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0493, -0.0003,  0.0856,  0.0288, -0.0341,  0.0255,  0.0311, -0.0423,\n",
       "         -0.0880,  0.0447,  0.0212, -0.0300, -0.0702, -0.0622,  0.0530, -0.0872,\n",
       "         -0.0450,  0.0307,  0.0512, -0.0617,  0.0226, -0.0037, -0.0180,  0.0512,\n",
       "         -0.0008,  0.0383,  0.0243, -0.0371, -0.0478,  0.0558,  0.0095,  0.0712,\n",
       "          0.0827, -0.0413, -0.0388,  0.0797, -0.0615,  0.0560, -0.0640,  0.0260,\n",
       "          0.0102,  0.0332, -0.0066,  0.0817, -0.0733,  0.0048,  0.0296,  0.0431,\n",
       "         -0.0597, -0.0557,  0.0327,  0.0565,  0.0204,  0.0544, -0.0766,  0.0823,\n",
       "         -0.0526, -0.0570,  0.0619,  0.0050,  0.0373,  0.0861,  0.0135, -0.0076,\n",
       "          0.0828,  0.0792,  0.0329, -0.0063, -0.0135, -0.0067, -0.0759,  0.0096,\n",
       "         -0.0294,  0.0088,  0.0716,  0.0004, -0.0840,  0.0380,  0.0816, -0.0652,\n",
       "         -0.0632, -0.0089, -0.0025,  0.0357], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0255,  0.0633, -0.1069,  0.0719,  0.0504, -0.0343,  0.1045,  0.0135,\n",
       "          -0.0534,  0.0260, -0.0741, -0.0420,  0.0457, -0.0361, -0.0015,  0.0349,\n",
       "           0.0387,  0.0447, -0.0832, -0.0851,  0.0959, -0.0586, -0.0939,  0.0271,\n",
       "           0.0395, -0.1023, -0.0990, -0.0536,  0.1051,  0.0923, -0.0383, -0.0119,\n",
       "           0.0329,  0.0978, -0.0280, -0.1001,  0.0169,  0.0497,  0.0281, -0.0871,\n",
       "           0.0470,  0.0732,  0.0377,  0.0042, -0.0862,  0.0071,  0.0630,  0.0724,\n",
       "          -0.0399, -0.1072, -0.0423, -0.0569, -0.0584,  0.0422,  0.0010, -0.0837,\n",
       "          -0.0637, -0.0553,  0.0251,  0.0956, -0.0981,  0.1035,  0.0724,  0.0698,\n",
       "          -0.0687,  0.0266,  0.1028,  0.0147, -0.0213,  0.0245,  0.0928,  0.0777,\n",
       "           0.0028, -0.0995, -0.0250, -0.0358,  0.0821, -0.0548, -0.0938, -0.0498,\n",
       "           0.0554,  0.0869,  0.0243,  0.0088],\n",
       "         [-0.1069,  0.0861, -0.0852, -0.0878, -0.0988, -0.0121, -0.0612,  0.0750,\n",
       "           0.0642,  0.0473,  0.0263, -0.0772, -0.0904,  0.1015, -0.0013, -0.0724,\n",
       "           0.0195,  0.0134, -0.0605, -0.0286, -0.0207,  0.0786,  0.0676, -0.0238,\n",
       "           0.0395,  0.0385, -0.0015,  0.0555, -0.0833,  0.0534, -0.0844, -0.0872,\n",
       "          -0.0478, -0.0682,  0.0384,  0.0140, -0.1088,  0.0788,  0.0836, -0.0225,\n",
       "           0.0987, -0.0339,  0.0838, -0.0240, -0.0019,  0.0804, -0.0652, -0.1058,\n",
       "           0.1071,  0.0669,  0.0233, -0.0349,  0.0689,  0.0365, -0.0052, -0.1024,\n",
       "           0.0790,  0.0674, -0.0705, -0.0701, -0.0307, -0.0943, -0.0082, -0.0497,\n",
       "           0.0278,  0.0681, -0.0347,  0.1051,  0.0706,  0.0078,  0.0116,  0.0362,\n",
       "           0.0423,  0.0575,  0.0076,  0.0542,  0.0470, -0.0874,  0.0487, -0.0098,\n",
       "           0.0101, -0.0398,  0.0016, -0.0420],\n",
       "         [-0.0580,  0.0586,  0.0415,  0.0518,  0.1047, -0.0981,  0.0400,  0.0138,\n",
       "          -0.0465,  0.0758,  0.0055,  0.0416, -0.0663, -0.0473, -0.0913, -0.0440,\n",
       "          -0.0483,  0.0809, -0.0323, -0.1053,  0.1079,  0.0168, -0.0688, -0.0080,\n",
       "          -0.0245,  0.0310, -0.0441, -0.0676,  0.0851, -0.0143,  0.0515,  0.0905,\n",
       "          -0.0760, -0.0957,  0.0639,  0.0848,  0.0026,  0.0892, -0.0799, -0.0771,\n",
       "          -0.0417, -0.0130,  0.0430, -0.0722,  0.0726, -0.0360, -0.0965, -0.1025,\n",
       "          -0.0245, -0.0724, -0.0419,  0.0059, -0.0767,  0.0224, -0.0963,  0.0474,\n",
       "           0.0897,  0.0625,  0.0604, -0.0398, -0.0378, -0.0666,  0.0411, -0.0947,\n",
       "          -0.0917,  0.0207,  0.0229, -0.1032,  0.0391,  0.0762, -0.0313,  0.0396,\n",
       "           0.0493,  0.0820, -0.0647, -0.0028,  0.0589,  0.0430,  0.0612, -0.0011,\n",
       "           0.0382,  0.0979, -0.0664,  0.0917],\n",
       "         [ 0.0997, -0.0203, -0.0998,  0.1088, -0.0939,  0.0334, -0.0558, -0.0777,\n",
       "          -0.1072,  0.1073, -0.0524, -0.0389, -0.0484,  0.0907,  0.1054,  0.0469,\n",
       "          -0.0178,  0.0128, -0.1078,  0.0958, -0.0629, -0.0630,  0.1007,  0.0124,\n",
       "           0.0368,  0.0562,  0.0822, -0.0506,  0.0391,  0.0204,  0.0627,  0.0369,\n",
       "           0.0340,  0.0204,  0.0130, -0.0327,  0.0100, -0.0390,  0.0440,  0.0485,\n",
       "          -0.0624,  0.0984,  0.0500,  0.0662,  0.0461, -0.0097,  0.0689, -0.0057,\n",
       "           0.0487,  0.0148,  0.0535, -0.0671,  0.0638, -0.0493, -0.0255,  0.0528,\n",
       "          -0.1075,  0.0701, -0.0731,  0.0715,  0.0981,  0.1067, -0.0886, -0.0496,\n",
       "          -0.0968, -0.1072, -0.0138,  0.0414, -0.0907,  0.0710,  0.0226, -0.0402,\n",
       "           0.0807,  0.0850, -0.0930,  0.0532,  0.0234,  0.0348, -0.0103, -0.1054,\n",
       "          -0.0702,  0.0648, -0.0312, -0.0792],\n",
       "         [ 0.0002,  0.0372, -0.0227,  0.0583, -0.0306,  0.0892,  0.0552,  0.0342,\n",
       "          -0.0108, -0.0942,  0.0689, -0.0238, -0.0450,  0.0444, -0.0602,  0.0286,\n",
       "          -0.0897,  0.0186,  0.0359, -0.0215,  0.0735, -0.0107, -0.0643, -0.0478,\n",
       "          -0.0130, -0.0954, -0.0237,  0.1002, -0.1053, -0.0624,  0.0287, -0.0484,\n",
       "           0.0351, -0.0588, -0.0308,  0.0069, -0.1009,  0.0677,  0.0614, -0.0033,\n",
       "          -0.0449, -0.0779,  0.0383,  0.0185, -0.0006, -0.0592,  0.0595, -0.0706,\n",
       "          -0.0297, -0.0856, -0.0768, -0.0984,  0.0479, -0.0414, -0.0560,  0.0201,\n",
       "          -0.0508,  0.0857,  0.1017, -0.0886, -0.0467,  0.1007,  0.0558,  0.0809,\n",
       "           0.0266,  0.0349,  0.0397, -0.0013,  0.0497, -0.0345, -0.0841, -0.0521,\n",
       "           0.0523,  0.0740, -0.0744, -0.0532,  0.0894, -0.0738,  0.0355,  0.1083,\n",
       "          -0.0580,  0.0377, -0.0189,  0.0077],\n",
       "         [ 0.0854, -0.0571,  0.0723, -0.1030,  0.0621,  0.0849, -0.0141,  0.0682,\n",
       "           0.0393,  0.0873,  0.0622, -0.0971, -0.0652, -0.0515, -0.0320, -0.0633,\n",
       "          -0.1009,  0.0767, -0.0909,  0.0460, -0.0734,  0.0161,  0.0872, -0.0953,\n",
       "           0.0709,  0.0523,  0.0517,  0.0926, -0.0088,  0.0005,  0.0485,  0.0386,\n",
       "          -0.0420, -0.0110, -0.1008,  0.0326,  0.0056,  0.0151,  0.0710,  0.0877,\n",
       "           0.0231, -0.0808,  0.0497,  0.1050,  0.1025,  0.0705,  0.1027,  0.0961,\n",
       "           0.0818, -0.0684,  0.0330,  0.0068, -0.0981, -0.0849,  0.0007, -0.1083,\n",
       "           0.1040,  0.0579, -0.0630,  0.1052, -0.1041,  0.0730, -0.0233, -0.0928,\n",
       "           0.0392, -0.0872,  0.0185, -0.0587, -0.0101,  0.0118,  0.0833, -0.0227,\n",
       "           0.0566, -0.0236, -0.0470, -0.0654,  0.0729,  0.0634,  0.0178,  0.0074,\n",
       "          -0.0653, -0.0204, -0.0003,  0.0021],\n",
       "         [-0.0501,  0.0072, -0.0331,  0.0260,  0.0088,  0.0917,  0.0411,  0.0656,\n",
       "          -0.0644,  0.0535,  0.0391,  0.0815, -0.0555,  0.0829, -0.0780,  0.0595,\n",
       "          -0.0076,  0.0127,  0.0985, -0.1056,  0.0622, -0.0082,  0.0348,  0.0744,\n",
       "          -0.0386,  0.1009,  0.0758, -0.0128, -0.0744, -0.0240, -0.0775, -0.0243,\n",
       "          -0.0920,  0.0107, -0.0992, -0.0056,  0.1082,  0.0006,  0.0653,  0.0768,\n",
       "          -0.0616,  0.1071,  0.0532, -0.0211,  0.0616,  0.0572, -0.0336,  0.0394,\n",
       "          -0.0241, -0.0625,  0.0081,  0.0244,  0.1081, -0.0863,  0.1080, -0.0423,\n",
       "           0.0833,  0.0968, -0.0464, -0.0118, -0.1039, -0.0549,  0.0262, -0.0857,\n",
       "           0.0461,  0.0581, -0.0443,  0.0011, -0.0773,  0.1007,  0.0546, -0.0256,\n",
       "          -0.0257,  0.0337, -0.0083,  0.1053, -0.0276,  0.0355, -0.0420,  0.0611,\n",
       "           0.0728, -0.0815,  0.0158,  0.0516],\n",
       "         [-0.1034, -0.0236, -0.0518, -0.0709,  0.0899, -0.0537, -0.0651, -0.0061,\n",
       "           0.0887,  0.0675, -0.0514, -0.0774,  0.0584, -0.0827, -0.0499, -0.1001,\n",
       "           0.0167,  0.1048,  0.0539, -0.0713, -0.1090,  0.0598, -0.0687,  0.0648,\n",
       "           0.0676,  0.0513, -0.0875, -0.0485,  0.0903,  0.0985, -0.0849,  0.0969,\n",
       "          -0.0799, -0.0002, -0.0818,  0.0263, -0.0939, -0.0271, -0.0008, -0.0906,\n",
       "           0.0169, -0.0706, -0.0489, -0.0350,  0.0226,  0.0369,  0.0353, -0.1047,\n",
       "           0.1062, -0.0602,  0.0131, -0.0342, -0.0081,  0.0566,  0.1088,  0.0065,\n",
       "          -0.0342, -0.0538, -0.0472,  0.0334,  0.0221,  0.0746,  0.0785, -0.0036,\n",
       "          -0.0049, -0.0944, -0.0619, -0.0758, -0.1082, -0.0158, -0.1016, -0.0781,\n",
       "           0.0801,  0.0706, -0.1069,  0.0923, -0.0026,  0.0428,  0.0673, -0.0085,\n",
       "           0.0189, -0.0967, -0.0959,  0.0981],\n",
       "         [-0.0981,  0.1022,  0.0058,  0.0359, -0.0540,  0.0020,  0.0607,  0.0588,\n",
       "           0.0158, -0.0755,  0.0027, -0.0598,  0.0162,  0.0278,  0.0859, -0.0349,\n",
       "           0.0648, -0.0401, -0.0946, -0.0923, -0.0625, -0.0734,  0.0802, -0.0764,\n",
       "           0.0091, -0.0904, -0.0475, -0.0925, -0.0206, -0.0648, -0.0795, -0.0391,\n",
       "           0.0511,  0.0687,  0.0593, -0.0623,  0.0519,  0.0222, -0.0756,  0.0135,\n",
       "           0.0582,  0.1033, -0.0344, -0.0562, -0.1018, -0.1049,  0.1076, -0.0040,\n",
       "          -0.0235, -0.1017, -0.0631, -0.0443,  0.0988,  0.0213, -0.0652,  0.0075,\n",
       "          -0.0780,  0.0005, -0.1035, -0.0115, -0.0043,  0.0849,  0.0214, -0.0567,\n",
       "          -0.0837,  0.1035,  0.1040, -0.0886,  0.0499,  0.0438, -0.0206, -0.0243,\n",
       "          -0.0450,  0.0328,  0.0193, -0.0500, -0.0529,  0.0282,  0.0099, -0.0413,\n",
       "          -0.0103, -0.0253, -0.0499,  0.0891],\n",
       "         [-0.1044, -0.0912, -0.1004,  0.0879, -0.0661, -0.1022,  0.1044, -0.1037,\n",
       "           0.0462,  0.0164, -0.0962,  0.0582, -0.0189,  0.0705, -0.0274,  0.0464,\n",
       "           0.0970,  0.0399, -0.0805, -0.0047,  0.0756,  0.0200, -0.1011,  0.0156,\n",
       "           0.0462,  0.0608, -0.0496,  0.0012,  0.0992, -0.0363,  0.0498,  0.0907,\n",
       "           0.0279, -0.1064,  0.0882,  0.0157, -0.0642,  0.0539,  0.0354,  0.0086,\n",
       "           0.0069, -0.0318, -0.0772, -0.0745, -0.0064, -0.0551,  0.0788, -0.0291,\n",
       "           0.0940,  0.0520,  0.0072,  0.0063, -0.0563,  0.0281,  0.0260, -0.0940,\n",
       "           0.0488, -0.0195,  0.1055, -0.0042, -0.0429, -0.1004,  0.0386,  0.0472,\n",
       "           0.0132, -0.0535,  0.0875,  0.0081, -0.0558,  0.0636,  0.0244, -0.0452,\n",
       "           0.0691, -0.0678,  0.0281,  0.0126, -0.0108,  0.0531, -0.0426,  0.0794,\n",
       "          -0.0648, -0.0793, -0.0735, -0.0039]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1090,  0.0259,  0.0609, -0.0163, -0.0080, -0.0246, -0.1039,  0.0724,\n",
       "          0.0429,  0.0837], requires_grad=True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1166, -0.0296,  0.0753, -0.0041, -0.0069,  0.0192, -0.0666,  0.0302,\n",
      "         -0.0053,  0.0900]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero the gradient buffers of all parameters and backprops with random gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
    "\n",
    "For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.\n",
    "\n",
    "If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recap:\n",
    "torch.Tensor - A multi-dimensional array with support for autograd operations like backward(). Also holds the gradient w.r.t. the tensor.\n",
    "\n",
    "nn.Module - Neural network module. Convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.\n",
    "\n",
    "nn.Parameter - A kind of Tensor, that is automatically registered as a parameter when assigned as an attribute to a Module.\n",
    "\n",
    "autograd.Function - Implements forward and backward definitions of an autograd operation. Every Tensor operation creates at least a single Function node that connects to functions that created a Tensor and encodes its history.\n",
    "\n",
    "At this point, we covered:\n",
    "* Defining a neural network\n",
    "* Processing inputs and calling backward\n",
    "\n",
    "Still Left:\n",
    "* Computing the loss\n",
    "* Updating the weights of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Function\n",
    "A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target.\n",
    "\n",
    "There are several different loss functions under the nn package . A simple loss is: nn.MSELoss which computes the mean-squared error between the input and the target.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output == out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randn(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9411, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you follow loss in the backward direction, using its .grad_fn attribute, you will see a graph of computations that looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d;\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear;\n",
    "      -> MSELoss;\n",
    "      -> loss;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, when we call loss.backward(), the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that has requires_grad=True will have their .grad Tensor accumulated with the gradient.\n",
    "\n",
    "For illustration, let us follow a few steps backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7f4489632748>\n",
      "<AddmmBackward object at 0x7f4489632588>\n",
      "<AccumulateGrad object at 0x7f4489632748>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0053,  0.0104,  0.0081,  0.0034, -0.0079,  0.0214])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing left to learn is:\n",
    "\n",
    "Updating the weights of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest update rule used in practice is the Stochastic Gradient Descent (SGD):\n",
    "\n",
    "weight = weight - learning_rate * gradient\n",
    "\n",
    "We can implement this using simple python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters(): #interate over all the learnable parameters of net\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: torch.optim that implements all these methods. Using it is very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how gradient buffers had to be manually set to zero using optimizer.zero_grad(). This is because gradients are accumulated as explained in Backprop section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(input)\n",
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8967, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss #loss is not small due to random input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
